# Project3SLBD
Mislabelling revisited in the context of lasso


Explore the effect of mislabelling in sparse logistic regression or a 
standard regression problem. Mislabelling for a regression problem
can be understood as a proportion of response values that are randomly 
or systematically permuted. Consider also especially a phenomena seen in 
the last mislabelling project: Flexible classifiers did often better for 
small to medium amounts of mislabelling while rigid classifiers did better
for large amounts of mislabelling. Penalisation with lambda can be seen
similarly: small lambda allows for more flexibility in model coefficients
whereas an increase in lambda leads to a more rigid model. 
Does this have the same effect as observed last time?
